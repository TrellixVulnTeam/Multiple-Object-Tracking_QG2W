{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stevenzc3/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import time\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary pwcnet (tfoptflow) functions\n",
    "\n",
    "sys.path.append(os.path.realpath('../tfoptflow/tfoptflow'))\n",
    "\n",
    "from model_pwcnet import ModelPWCNet, _DEFAULT_PWCNET_TEST_OPTIONS\n",
    "from visualize import plot_img_pairs_w_flows\n",
    "from optflow import flow_to_img, flow_write_as_png\n",
    "\n",
    "CKPT_PATH = '../../pwcnet/pwcnet_sm/pwcnet.ckpt-592000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_in_path = '/mnt/disks/tensorflow-disk/video_distillation/hockey1/hockey1002.mp4'\n",
    "video_in_path = '/mnt/disks/tensorflow-disk/video_distillation/giraffe1/giraffe1000.mp4'\n",
    "max_frames = 1001\n",
    "training_stride = 8\n",
    "# detection_path = '/mnt/disks/tensorflow-disk/video_distillation/hockey1/detectron_large_mask_rcnn_1_hockey1002.npy'\n",
    "detection_path = '/mnt/disks/tensorflow-disk/video_distillation/giraffe1/detectron_large_mask_rcnn_1_giraffe1000.npy'\n",
    "stats_path = None\n",
    "start_frame = 0\n",
    "height = 1080\n",
    "width = 1920"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import helper functions from online_scene_seg\n",
    "\n",
    "# TODO: these are copied over because online_scene_seg as relative imports that\n",
    "# don't work with this notebook's path.\n",
    "\n",
    "def get_class_groups():\n",
    "    people_cls = [1]\n",
    "    twowheeler_cls = [2, 4]\n",
    "    vehicle_cls = [3, 6, 7, 8]\n",
    "\n",
    "    #(40, 'bottle')\n",
    "    #(41, 'wine glass')\n",
    "    #(42, 'cup')\n",
    "    #(43, 'fork')\n",
    "    #(44, 'knife')\n",
    "    #(45, 'spoon')\n",
    "    #(46, 'bowl')\n",
    "\n",
    "    utensils_cls = [40, 41, 42, 43, 44, 45, 46]\n",
    "\n",
    "    #(14, 'bench')\n",
    "    #(57, 'chair')\n",
    "    #(58, 'couch')\n",
    "    #(61, 'dining table')\n",
    "    furniture_cls = [14, 57, 58, 61]\n",
    "\n",
    "    fine_classes = False\n",
    "    \n",
    "    if fine_classes:\n",
    "        cls = [1, 2, 4, 10, 40, 42, 46, 57, 61]\n",
    "        class_groups = [[x] for x in cls]\n",
    "        class_groups.append([3, 6, 8])\n",
    "    else:\n",
    "        class_groups = [people_cls, twowheeler_cls, vehicle_cls, utensils_cls, furniture_cls]\n",
    "\n",
    "    # just detect people and giraffes\n",
    "    class_groups = [people_cls, [24]]\n",
    "        \n",
    "    return class_groups\n",
    "\n",
    "def update_stats(labels, pred_vals, class_tp, class_fp, class_fn,\n",
    "                 class_total, class_correct, weight_mask, frame_stats,\n",
    "                 entropy_vals, frame_id):\n",
    "    eps = 1e-06\n",
    "    num_classes = len(class_total)\n",
    "    curr_tp = np.zeros(num_classes, np.float32)\n",
    "    curr_fp = np.zeros(num_classes, np.float32)\n",
    "    curr_fn = np.zeros(num_classes, np.float32)\n",
    "    curr_iou = np.zeros(num_classes, np.float32)\n",
    "    curr_correct = np.zeros(num_classes, np.float32)\n",
    "    curr_total = np.zeros(num_classes, np.float32)\n",
    "    correct_mask = (pred_vals == labels)\n",
    "\n",
    "    for g in range(num_classes):\n",
    "        cls_mask = np.logical_and((labels == g), weight_mask)\n",
    "        cls_tp_mask = np.logical_and(cls_mask, correct_mask)\n",
    "        cls_tp = np.sum(cls_tp_mask)\n",
    "        curr_tp[g] = cls_tp\n",
    "        class_tp[g] = class_tp[g] + cls_tp\n",
    "\n",
    "        cls_total = np.sum(cls_mask)\n",
    "        curr_total[g] = cls_total\n",
    "        curr_correct[g] = cls_tp\n",
    "        class_total[g] = class_total[g] + cls_total\n",
    "        class_correct[g] = class_correct[g] + cls_tp\n",
    "\n",
    "        pred_mask = np.logical_and((pred_vals == g), weight_mask)\n",
    "        cls_fp_mask = np.logical_and(np.logical_not(cls_mask), pred_mask)\n",
    "        cls_fn_mask = np.logical_and(cls_mask, np.logical_not(pred_mask))\n",
    "\n",
    "        cls_fp = np.sum(cls_fp_mask)\n",
    "        cls_fn = np.sum(cls_fn_mask)\n",
    "        curr_fp[g] = cls_fp\n",
    "        curr_fn[g] = cls_fn\n",
    "        class_fp[g] = class_fp[g] + cls_fp\n",
    "        class_fn[g] = class_fn[g] + cls_fn\n",
    "\n",
    "        cls_iou = (cls_tp + eps) / (cls_tp + cls_fp + cls_fn + eps)\n",
    "        curr_iou[g] = cls_iou\n",
    "\n",
    "    frame_stats[frame_id] = { 'tp': curr_tp,\n",
    "                              'fp': curr_fp,\n",
    "                              'fn': curr_fn,\n",
    "                              'iou': curr_iou,\n",
    "                              'correct': curr_correct,\n",
    "                              'total': curr_total,\n",
    "                              'average_entropy': entropy_vals}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask R-CNN utilities\n",
    "\n",
    "sys.path.append(os.path.realpath('../datasets'))\n",
    "sys.path.append(os.path.realpath('../utils'))\n",
    "\n",
    "from mask_rcnn_tfrecords import get_dataset, batch_segmentation_masks,\\\n",
    "                                visualize_masks\n",
    "from mask_rcnn_stream import MaskRCNNSequenceStream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "WARNING:tensorflow:From /home/stevenzc3/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/initializers.py:104: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with distribution=normal is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`normal` is a deprecated alias for `truncated_normal`\n",
      "... model built.\n",
      "Loading model checkpoint ../../pwcnet/pwcnet_sm/pwcnet.ckpt-592000 for eval or testing...\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from ../../pwcnet/pwcnet_sm/pwcnet.ckpt-592000\n",
      "... model loaded\n"
     ]
    }
   ],
   "source": [
    "# initialize PWCNet in test mode\n",
    "\n",
    "nn_opts = deepcopy(_DEFAULT_PWCNET_TEST_OPTIONS)\n",
    "nn_opts['verbose'] = True\n",
    "nn_opts['ckpt_path'] = CKPT_PATH\n",
    "nn_opts['batch_size'] = 1\n",
    "nn_opts['gpu_devices'] = ['/device:GPU:0']\n",
    "nn_opts['controller'] = '/device:GPU:0'\n",
    "nn_opts['use_dense_cx'] = False\n",
    "nn_opts['use_res_cx'] = False\n",
    "nn_opts['pyr_lvls'] = 6\n",
    "nn_opts['flow_pred_lvl'] = 2\n",
    "\n",
    "# since the model generates flow padded to multiples of 64\n",
    "# reduce back to the input video size\n",
    "nn_opts['adapt_info'] = (1, height, width, 2)\n",
    "\n",
    "nn = ModelPWCNet(mode='test', options=nn_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow_cython import flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt/disks/tensorflow-disk/video_distillation/giraffe1/giraffe1000.mp4']\n",
      "Parent prediction:  0\n",
      "time 6.297091722488403\n",
      "1 0.77006567\n",
      "time 0.17461037635803223\n",
      "2 0.67289966\n",
      "time 0.18724918365478516\n",
      "3 0.6278668\n",
      "time 0.18098068237304688\n",
      "4 0.58880424\n",
      "time 0.16969704627990723\n",
      "5 0.545571\n",
      "time 0.1761150360107422\n",
      "6 0.47822094\n",
      "time 0.18421149253845215\n",
      "7 0.38723433\n",
      "Parent prediction:  8\n",
      "time 0.16814088821411133\n",
      "9 0.65053463\n",
      "time 0.17323827743530273\n",
      "10 0.47578785\n",
      "time 0.17032361030578613\n",
      "11 0.43177098\n",
      "time 0.16793465614318848\n",
      "12 0.40003175\n",
      "time 0.1685318946838379\n",
      "13 0.3845975\n",
      "time 0.1739511489868164\n",
      "14 0.37175918\n",
      "time 0.1699848175048828\n",
      "15 0.34728244\n",
      "Parent prediction:  16\n",
      "time 0.17185568809509277\n",
      "17 0.84512323\n",
      "time 0.17558884620666504\n",
      "18 0.7479621\n",
      "time 0.18017172813415527\n",
      "19 0.6731222\n",
      "time 0.17629694938659668\n",
      "20 0.6184462\n",
      "time 0.16859865188598633\n",
      "21 0.56417906\n",
      "time 0.16857266426086426\n",
      "22 0.51135755\n",
      "time 0.16977238655090332\n",
      "23 0.45751446\n",
      "Parent prediction:  24\n",
      "time 0.17063426971435547\n",
      "25 0.8640995\n",
      "time 0.17356586456298828\n",
      "26 0.8075421\n",
      "time 0.17296600341796875\n",
      "27 0.75036377\n",
      "time 0.1684708595275879\n",
      "28 0.7095852\n",
      "time 0.17262005805969238\n",
      "29 0.6676666\n",
      "time 0.17462778091430664\n",
      "30 0.63702554\n",
      "time 0.16874074935913086\n",
      "31 0.5866627\n",
      "Parent prediction:  32\n",
      "time 0.15344452857971191\n",
      "33 0.9267054\n",
      "time 0.17665791511535645\n",
      "34 0.8889815\n",
      "time 0.1752028465270996\n",
      "35 0.85589266\n",
      "time 0.16686344146728516\n",
      "36 0.8210038\n",
      "time 0.1733083724975586\n",
      "37 0.7965402\n",
      "time 0.17409586906433105\n",
      "38 0.76074755\n",
      "time 0.16770458221435547\n",
      "39 0.72729665\n",
      "Parent prediction:  40\n",
      "time 0.17727327346801758\n",
      "41 0.8973562\n",
      "time 0.16991686820983887\n",
      "42 0.852482\n",
      "time 0.1835954189300537\n",
      "43 0.8133912\n",
      "time 0.17171788215637207\n",
      "44 0.776176\n",
      "time 0.17225146293640137\n",
      "45 0.7472399\n",
      "time 0.1719977855682373\n",
      "46 0.7185364\n",
      "time 0.17185664176940918\n",
      "47 0.6950302\n",
      "Parent prediction:  48\n",
      "time 0.17107129096984863\n",
      "49 0.9418935\n",
      "time 0.1758255958557129\n",
      "50 0.90951675\n",
      "time 0.1719672679901123\n",
      "51 0.8794748\n",
      "time 0.17294812202453613\n",
      "52 0.8612539\n",
      "time 0.16904997825622559\n",
      "53 0.84015745\n",
      "time 0.1782820224761963\n",
      "54 0.8059757\n",
      "time 0.17478251457214355\n",
      "55 0.7810666\n",
      "Parent prediction:  56\n",
      "time 0.18083977699279785\n",
      "57 0.9329503\n",
      "time 0.17252731323242188\n",
      "58 0.9002766\n",
      "time 0.16964936256408691\n",
      "59 0.86455613\n",
      "time 0.173234224319458\n",
      "60 0.8349695\n",
      "time 0.17649340629577637\n",
      "61 0.80872375\n",
      "time 0.1726388931274414\n",
      "62 0.7901981\n",
      "time 0.17482495307922363\n",
      "63 0.7663488\n",
      "Parent prediction:  64\n",
      "time 0.17180562019348145\n",
      "65 0.9166493\n",
      "time 0.17383360862731934\n",
      "66 0.87498045\n",
      "time 0.17282867431640625\n",
      "67 0.8343557\n",
      "time 0.17727041244506836\n",
      "68 0.80574614\n",
      "time 0.17037749290466309\n",
      "69 0.7682804\n",
      "time 0.17045021057128906\n",
      "70 0.7310657\n",
      "time 0.17484712600708008\n",
      "71 0.69670445\n",
      "Parent prediction:  72\n",
      "time 0.17431402206420898\n",
      "73 0.92741024\n",
      "time 0.17028546333312988\n",
      "74 0.86503494\n",
      "time 0.17456603050231934\n",
      "75 0.8215177\n",
      "time 0.17110991477966309\n",
      "76 0.7790786\n",
      "time 0.1738126277923584\n",
      "77 0.7177701\n",
      "time 0.17412233352661133\n",
      "78 0.66942483\n",
      "time 0.17312002182006836\n",
      "79 0.6203479\n",
      "Parent prediction:  80\n",
      "time 0.17166519165039062\n",
      "81 0.8756206\n",
      "time 0.17374277114868164\n",
      "82 0.7991179\n",
      "time 0.17260456085205078\n",
      "83 0.7216721\n",
      "time 0.17145729064941406\n",
      "84 0.6631995\n",
      "time 0.16882896423339844\n",
      "85 0.60794723\n",
      "time 0.17683935165405273\n",
      "86 0.55450255\n",
      "time 0.1724531650543213\n",
      "87 0.51204985\n",
      "Parent prediction:  88\n",
      "time 0.1720583438873291\n",
      "89 0.9066903\n",
      "time 0.17030739784240723\n",
      "90 0.8582279\n",
      "time 0.1697709560394287\n",
      "91 0.81801134\n",
      "time 0.1719813346862793\n",
      "92 0.7865802\n",
      "time 0.17494630813598633\n",
      "93 0.750825\n",
      "time 0.16838812828063965\n",
      "94 0.73078454\n",
      "time 0.1746504306793213\n",
      "95 0.7062116\n",
      "Parent prediction:  96\n",
      "time 0.17224502563476562\n",
      "97 0.9363609\n",
      "time 0.17479610443115234\n",
      "98 0.9000419\n",
      "time 0.17612910270690918\n",
      "99 0.87023234\n",
      "time 0.1725003719329834\n",
      "100 0.851835\n",
      "time 0.17172574996948242\n",
      "101 0.83751374\n",
      "time 0.17742419242858887\n",
      "102 0.81413096\n",
      "time 0.17396259307861328\n",
      "103 0.7888476\n",
      "Parent prediction:  104\n",
      "time 0.17252683639526367\n",
      "105 0.9269445\n",
      "time 0.17031645774841309\n",
      "106 0.8933567\n",
      "time 0.16946649551391602\n",
      "107 0.8709077\n",
      "time 0.17438220977783203\n",
      "108 0.856299\n",
      "time 0.1755390167236328\n",
      "109 0.8339543\n",
      "time 0.17093324661254883\n",
      "110 0.8176715\n",
      "time 0.16765594482421875\n",
      "111 0.81102175\n",
      "Parent prediction:  112\n",
      "time 0.1725597381591797\n",
      "113 0.9007297\n",
      "time 0.16945719718933105\n",
      "114 0.85801584\n",
      "time 0.18041658401489258\n",
      "115 0.84732884\n",
      "time 0.17629241943359375\n",
      "116 0.8158736\n",
      "time 0.17423033714294434\n",
      "117 0.79829794\n",
      "time 0.1692335605621338\n",
      "118 0.77891195\n",
      "time 0.16987323760986328\n",
      "119 0.75105304\n",
      "Parent prediction:  120\n",
      "time 0.178574800491333\n",
      "121 0.9156532\n",
      "time 0.1766817569732666\n",
      "122 0.86709154\n",
      "time 0.1757824420928955\n",
      "123 0.8264948\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-68d8291dd69b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m         pred_flows = nn.predict_from_img_pairs([(prev_frame, frame)], \n\u001b[1;32m     64\u001b[0m                                                \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                                                verbose=False)\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;31m# shape: (height, width, 2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mpred_flow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_flows\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/JITNet/tfoptflow/tfoptflow/model_pwcnet.py\u001b[0m in \u001b[0;36mpredict_from_img_pairs\u001b[0;34m(self, img_pairs, batch_size, verbose)\u001b[0m\n\u001b[1;32m    998\u001b[0m                 \u001b[0;31m# Run the adapted samples through the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m                 \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_tnsr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_adapt\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1000\u001b[0;31m                 \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_hat_test_tnsr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1001\u001b[0m                 \u001b[0my_hats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostproc_y_hat_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_adapt_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1276\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# read in both the video and the detections using stream\n",
    "video_files = [video_in_path]\n",
    "detections_paths = [detection_path]\n",
    "\n",
    "input_streams = MaskRCNNSequenceStream(video_files, \n",
    "                                       detections_paths,\n",
    "                                       start_frame=start_frame, \n",
    "                                       stride=1)\n",
    "\n",
    "# get the class groups\n",
    "class_groups = get_class_groups()\n",
    "\n",
    "# initialize the metrics\n",
    "\n",
    "curr_frame = 0\n",
    "prev_frame = None\n",
    "prev_in_frame = None\n",
    "pred = None\n",
    "per_frame_stats = {}\n",
    "num_classes = len(class_groups) + 1\n",
    "\n",
    "class_correct = np.zeros(num_classes, np.float32)\n",
    "class_total = np.zeros(num_classes, np.float32)\n",
    "class_tp = np.zeros(num_classes, np.float32)\n",
    "class_fp = np.zeros(num_classes, np.float32)\n",
    "class_fn = np.zeros(num_classes, np.float32)\n",
    "class_iou = np.zeros(num_classes, np.float32)\n",
    "\n",
    "pos_matrix = np.zeros(width * height)\n",
    "for i in range(width * height):\n",
    "    pos_matrix[i] = i\n",
    "pos_matrix_idx = np.int32(pos_matrix)\n",
    "\n",
    "for frame, boxes, classes, scores, masks, num_objects, frame_id in input_streams:\n",
    "    \n",
    "    if curr_frame >= max_frames:\n",
    "        break\n",
    "   \n",
    "    \n",
    "    boxes = np.expand_dims(boxes, axis=0)\n",
    "    classes = np.expand_dims(classes, axis=0)\n",
    "    scores = np.expand_dims(scores, axis=0)\n",
    "    masks = np.expand_dims(masks, axis=0)\n",
    "    num_objects = np.expand_dims(num_objects, axis=0)\n",
    "    \n",
    "    labels_vals, _ = batch_segmentation_masks(1,\n",
    "                                              (height, width),\n",
    "                                              boxes, classes, masks, scores,\n",
    "                                              num_objects, True,\n",
    "                                              class_groups)\n",
    "    labels_val = np.reshape(labels_vals, (height, width))\n",
    "    if prev_frame is None:\n",
    "        prev_frame = frame\n",
    "    \n",
    "    if curr_frame % training_stride == 0:\n",
    "        pred = labels_val\n",
    "        pred_ext = np.reshape(pred, (1, height, width))\n",
    "        gt_pred = labels_val\n",
    "        gt_im = frame\n",
    "    else:\n",
    "        # compute forward flow\n",
    "        start = time.time()\n",
    "        pred_flows = nn.predict_from_img_pairs([(prev_frame, frame)], \n",
    "                                               batch_size=1, \n",
    "                                               verbose=False)\n",
    "        # shape: (height, width, 2)\n",
    "        pred_flow = np.round(pred_flows[0]).astype(np.int32)\n",
    "        \n",
    "        # Cython function\n",
    "        pred = flow(pred, pred_flow)\n",
    "        end = time.time()\n",
    "    \n",
    "        # update stats\n",
    "        pred_ext = np.reshape(pred, (1, height, width))\n",
    "        update_stats(labels_vals, pred_ext, class_tp, class_fp, class_fn,\n",
    "                     class_total, class_correct, np.ones(labels_vals.shape, dtype=np.bool),\n",
    "                     per_frame_stats, None, curr_frame)\n",
    "        \n",
    "    # visualize predictions\n",
    "#     vis_shape = (height, width, 3)\n",
    "#     vis_labels = visualize_masks(pred_ext, 1, vis_shape,\n",
    "#                                  num_classes=num_classes)\n",
    "#     vis_labels = vis_labels[0]\n",
    "#     labels_image = cv2.addWeighted(frame, 0.5, vis_labels, 0.5, 0)\n",
    "\n",
    "#     fig = plt.figure(figsize=(16, 9))\n",
    "#     ax = fig.add_subplot(111)\n",
    "#     ax.set_aspect(7)\n",
    "#     ax.imshow(labels_image)\n",
    "#     # plt.show()\n",
    "    \n",
    "#     fig.savefig('/home/stevenzc3/giraffe_flow/{:03d}.png'.format(curr_frame))\n",
    "#     plt.close()\n",
    "    \n",
    "    # end = time.time()\n",
    "    prev_frame = frame\n",
    "    if curr_frame in per_frame_stats:\n",
    "        print('time', end - start)\n",
    "        print(curr_frame, per_frame_stats[curr_frame][\"iou\"][1])\n",
    "    else:\n",
    "        print(\"Parent prediction: \", curr_frame)\n",
    "    curr_frame += 1\n",
    "\n",
    "if stats_path:\n",
    "    np.save(stats_path, [per_frame_stats])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
