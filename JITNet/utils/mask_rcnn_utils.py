import cv2
import numpy as np

def get_full_resolution_mask(bbox, mask, image_shape, threshold=0.5,
                             scale_boxes=False):
    y1, x1, y2, x2 = bbox
    if scale_boxes:
        y1 = int(y1 * (image_shape[0]))
        y2 = int(y2 * (image_shape[0]))
        x1 = int(x1 * (image_shape[1]))
        x2 = int(x2 * (image_shape[1]))
    mask = cv2.resize(mask, (x2 - x1, y2 - y1)).astype(np.float32)

    thresh_mask = np.where(mask >= threshold, 1, 0)
    full_mask = np.zeros((image_shape[0], image_shape[1]), dtype=np.bool)
    full_mask[y1:y2, x1:x2] = thresh_mask

    return full_mask

def mask_rcnn_match_mask(bbox, mask, target_mask, image_shape, threshold=0.5):
    full_mask = get_full_resolution_mask(bbox, mask, image_shape,
                                         threshold = threshold)

    intersection = np.sum(np.bitwise_and(full_mask, target_mask))
    overlap = np.sum(np.bitwise_or(full_mask, target_mask))

    eps = 1e-06
    iou = (float(intersection)/(overlap + eps))
    return iou

def mask_rcnn_unmold_mask(mask, bbox, image_shape, idx, full_masks,
                          box_masks, compute_box_mask=False, dialate=True,
                          threshold = 0.5):
    """Converts a mask generated by the neural network into a format similar
    to it's original shape.
    mask: [height, width] of type float. A small, typically 28x28 mask.
    bbox: [y1, x1, y2, x2]. The box to fit the mask in.

    Returns a binary or weighted mask with the same size as the original image.
    """
    y1, x1, y2, x2 = bbox
    mask = cv2.resize(mask, (x2 - x1, y2 - y1)).astype(np.float32)

    thresh_mask = np.where(mask >= threshold, 1, 0).astype(np.uint8)
    # Put the mask in the right location.
    full_masks[idx, y1:y2, x1:x2] = thresh_mask

    if box_masks is not None:
        if dialate:
            dialate_frac = 0.15
            dy1 = max(int(y1 - dialate_frac * (y2 - y1)), 0)
            dx1 = max(int(x1 - dialate_frac * (x2 - x1)), 0)

            dy2 = min(int(y2 + dialate_frac * (y2 - y1)), image_shape[0])
            dx2 = min(int(x2 + dialate_frac * (x2 - x1)), image_shape[1])

            mask = cv2.resize(mask, (dx2 - dx1, dy2 - dy1)).astype(np.float32)
            box_masks[idx, dy1:dy2, dx1:dx2] = np.where(mask >= 0, 1, 0).astype(np.uint8)
        else:
            box_masks[idx, y1:y2, x1:d2] = np.where(mask >= 0, 1, 0).astype(np.uint8)

def mask_rcnn_get_full_masks(boxes, masks, image_shape, box_mask=False, threshold=0.5):
    N = len(boxes)
    # Resize masks to original image size and set boundary threshold.
    full_masks = np.zeros((N, image_shape[0], image_shape[1]), dtype=np.uint8)
    box_masks = np.zeros((N, image_shape[0], image_shape[1]), dtype=np.uint8)

    for i in range(N):
        # Convert neural network mask to full size mask
        mask_rcnn_unmold_mask(masks[i], boxes[i], image_shape, i, full_masks,
                              box_masks, compute_box_mask=box_mask, threshold=threshold)

    return full_masks, box_masks

def bb_intersection_over_union(boxA, boxB):
    # determine the (x, y)-coordinates of the intersection rectangle
    xA = max(boxA[0], boxB[0])
    yA = max(boxA[1], boxB[1])
    xB = min(boxA[2], boxB[2])
    yB = min(boxA[3], boxB[3])

    # compute the area of intersection rectangle
    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)

    # compute the area of both the prediction and ground-truth
    # rectangles
    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)
    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)

    # compute the intersection over union by taking the intersection
    # area and dividing it by the sum of prediction + ground-truth
    # areas - the interesection area
    iou = interArea / float(boxAArea + boxBArea - interArea)

    # return the intersection over union value
    return iou

def mask_rcnn_get_best_box_match(boxes, masks, scores,
                                 query_box,
                                 image_shape,
                                 scale_boxes=True,
                                 box_threshold=0.5,
                                 match_threshold=0.5):
    h = image_shape[0]
    w = image_shape[1]

    boxes = boxes.copy()

    if scale_boxes:
        boxes[:, 0] = boxes[:, 0] * h
        boxes[:, 2] = boxes[:, 2] * h
        boxes[:, 1] = boxes[:, 1] * w
        boxes[:, 3] = boxes[:, 3] * w

        query_box = query_box.copy()
        query_box[0] = int(query_box[0] * h)
        query_box[2] = int(query_box[2] * h)
        query_box[1] = int(query_box[1] * w)
        query_box[3] = int(query_box[3] * w)

    boxes = boxes.astype(np.int32)

    N = len(boxes)
    best_match_idx = -1
    best_iou = 0.0
    best_area = 0.0

    for i in range(N):
        if scores[i] < box_threshold:
            continue
        curr_iou = bb_intersection_over_union(boxes[i], query_box)
        if curr_iou > best_iou and curr_iou > match_threshold:
            best_match_idx = i
            best_iou = curr_iou
            best_area = (boxes[i][2] - boxes[i][0]) * (boxes[i][3] - boxes[i][1])

    return best_match_idx, best_iou, best_area


def mask_rcnn_get_best_attention_match(boxes, masks, scores,
                                      attn_mask,
                                      image_shape,
                                      scale_boxes=True,
                                      box_threshold=0.5,
                                      match_threshold=0.5,
                                      mask_threshold=0.5):
    h = image_shape[0]
    w = image_shape[1]

    boxes = boxes.copy()

    if scale_boxes:
        boxes[:, 0] = boxes[:, 0] * h
        boxes[:, 2] = boxes[:, 2] * h
        boxes[:, 1] = boxes[:, 1] * w
        boxes[:, 3] = boxes[:, 3] * w

    boxes = boxes.astype(np.int32)

    N = len(boxes)
    best_match_idx = -1
    best_iou = 0.0
    best_area = 0.0

    for i in range(N):
        if scores[i] < box_threshold:
            continue
        curr_iou = mask_rcnn_match_mask(boxes[i], masks[i], attn_mask,
                                        image_shape, threshold=mask_threshold)
        if curr_iou > best_iou and curr_iou > match_threshold:
            best_match_idx = i
            best_iou = curr_iou
            best_area = (boxes[i][2] - boxes[i][0]) * (boxes[i][3] - boxes[i][1])

    return best_match_idx, best_iou, best_area

def mask_rcnn_unmold_cls_mask(mask, bbox, image_shape, idx, full_masks,
                              box_masks, cls, compute_box_mask=False,
                              dialate=True, threshold = 0.5):
    """Converts a mask generated by the neural network into a format similar
    to it's original shape.
    mask: [height, width] of type float. A small, typically 28x28 mask.
    bbox: [y1, x1, y2, x2]. The box to fit the mask in.

    Returns a binary or weighted mask with the same size as the original image.
    """
    y1, x1, y2, x2 = bbox
    if (x2 - x1) <= 0 or (y2 - y1) <= 0:
        return

    mask = cv2.resize(mask, (x2 - x1, y2 - y1)).astype(np.float32)

    thresh_mask = np.where(np.logical_and(mask >= threshold,
                                          cls > full_masks[y1:y2, x1:x2]),
                                          cls, full_masks[y1:y2, x1:x2]).astype(np.uint8)
    # Put the mask in the right location.
    full_masks[y1:y2, x1:x2] = thresh_mask

    if box_masks is not None:
        if dialate:
            dialate_frac = 0.15
            dy1 = max(int(y1 - dialate_frac * (y2 - y1)), 0)
            dx1 = max(int(x1 - dialate_frac * (x2 - x1)), 0)

            dy2 = min(int(y2 + dialate_frac * (y2 - y1)), image_shape[0])
            dx2 = min(int(x2 + dialate_frac * (x2 - x1)), image_shape[1])

            mask = cv2.resize(mask, (dx2 - dx1, dy2 - dy1)).astype(np.float32)
            box_masks[dy1:dy2, dx1:dx2] = np.where(mask >= 0, 1, 0).astype(np.bool)
        else:
            box_masks[y1:y2, x1:d2] = np.where(mask >= 0, 1, 0).astype(np.bool)

def mask_rcnn_single_mask(boxes, classes, scores, masks, image_shape,
                          box_mask=False, box_threshold=0.5,
                          mask_threshold=0.5):
    N = len(boxes)
    # Resize masks to original image size and set boundary threshold.
    full_masks = np.zeros((image_shape[0], image_shape[1]), dtype=np.uint8)
    box_masks = np.zeros((image_shape[0], image_shape[1]), dtype=np.bool)

    for i in range(N):
        if scores[i] < box_threshold:
            continue
        # Convert neural network mask to full size mask
        mask_rcnn_unmold_cls_mask(masks[i], boxes[i], image_shape,
                                  i, full_masks,
                                  box_masks, classes[i],
                                  compute_box_mask=box_mask,
                                  threshold=mask_threshold)
    return full_masks, box_masks
